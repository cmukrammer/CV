function [out, act_h, act_a] = Forward(W, b, X)
% [OUT, act_h, act_a] = Forward(W, b, X) performs forward propogation on the
% input data 'X' uisng the network defined by weights and biases 'W' and 'b'
% (as generated by InitializeNetwork(..)).
%
% This function should return the final softmax output layer activations in OUT,
% as well as the hidden layer post activations in 'act_h', and the hidden layer
% pre activations in 'act_a'.

t = X;
act_a = cell(1,size(W,2));
act_h = cell(1,size(W,2));

for i=1:size(W,2)-1
    t = t*W{i} + b{i};
    act_a{i} = t;
    act_h{i} = sigmf(t,[1 0]);
    t = act_h{i};
end

t = t*W{size(W,2)} + b{size(W,2)};
act_a{size(W,2)} = t;
t = exp(t);
den = sum(t);
out = t/den;
act_h{size(W,2)} = out;
out = out';

end
